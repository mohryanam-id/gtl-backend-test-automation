# Backend Test Automation Assignment

## Summary

- dummyapi to help simulating the endpoint, It is using OpenAPI specs and Flask.
- Requests module and Pytest Framework for the testing, and Allure Framework for the reporting.
- The flow to compare the file is like below:

```text
check unique keys --> check other values --> create the result to the report
```

## Description

This is Automated API Testing for comparing two CSV files returned by the /getSecuritiesList API, where one file is generated by the latest master version of the application and the other file is generated by the last released version of the application. The purpose of this script is to perform regression testing for the functionality during every release.

## Getting Started

- Install python (<https://realpython.com/courses/installing-python-windows-macos-linux/>)
- Clone this repository to your local machine.
- Run Terminal/Powershell
- Change directory to the repository
- Install Allure Framework (<https://docs.qameta.io/allure/>)
- Open another terminal
- Change directory to the repository again
- [Optional] Create virtual environment and Activate it (<https://realpython.com/python-virtual-environments-a-primer/>)

- Install the required packages by running

```bash
pip3 install -r requirements.txt
```

or

```bash
pip install -r requirements.txt
```

- Run the script by executing

```bash
python3 dummyapi/app.py
```

or

```bash
python dummyapi/app.py
```

- check if the dummyapi is ready by open the url http://localhost:7777 on your browser

## Usage

- Open Terminal/Powershell
- Change directory to the repository
- [Mandatory if it's created] Activate virtual environment
- Run pytest

```bash
pytest
```

- Run Allure by executing

```bash
allure serve ./report/allure
```

## Output

The code will output an allure report showing the differences between the two CSV files on the test cases, if any. If there are no differences, the report will indicate that the two files are identical.

## Improvements

Some possible improvements to this code include:

- Adding more error handling to the code to handle potential errors.
- Adding more functionality to the code to log errors and other events.
- Providing more options for configuring the code, such as setting the column names dynamically.
- Adding more tests to cover edge cases and potential errors.
- Refactoring the code.
- Use dockerization
- Use AI to check false-positive or false-negative
- CI/CD integration

## Criteria

- [x] Solution should be scalable(Should support fast changing product features and requirements and large no of future/current test cases).
- [ ] Choose efficient design patterns. Elaborate the choice in a README file.
      Despite the code is not using any designs pattern implicitly, the code can be refactored to use design patterns such as: template method to test\*.py files, singleton to read config file, etc.
- [x] Use OOP concepts where you see required.
- [x] Choose the techstack with consideration for Maintainability/Usability/Reporting/Readability.

- Solution should adhere to SOLID principles.
- README file should include the steps to run the tests, the brief description of the approach or any alternative considered and any other dependency.
- What improvements would be needed for the solution to be platform/OS independent.

## Notes

- [x] Tested on Windows
- [x] Tested on Macos
- [x] Parallel Execution
